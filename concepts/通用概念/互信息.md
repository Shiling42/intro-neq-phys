互信息(mutual information)刻画了多随机变量之间的耦合关系.

对于两个随机变量 $X$ 和 $Y$, 其互信息的定义为

$$
I(X;Y)= \int_X\int_Y \rho(x,y)\ln\frac{\rho(x,y)}{\rho(x)\rho(y)}
$$

直接处理一下, 我们能将其拆解为各个部分的熵
$$
I(X;Y) = H(X)+H(Y)-H(X,Y)
$$要理解互信息我们需要引入一点贝叶斯定理

$$
\rho(x,y) = \rho(x|y)\rho(x) = \rho(x|y)p(y)
$$

然后利用贝叶斯定理, 我们处理一下互信息

$$
\begin{aligned}
I(X;Y)
&=\int_X\int_Y \rho(x,y)\ln\frac{\rho(x|y)}{\rho(x)}\\
& = \int_X\int_Y\rho(x,y)\ln \rho(x|y)-\int_X\rho(x)\ln \rho(x)\\
&=  \int_X\int_Y\rho(x|y)p(x)\ln \rho(x|y) +H(X)\\
&= H(X) - H(X|Y) 
\end{aligned}
$$
所以互信息可以理解为一种信息差? 我们需要进一步理解互信息和[[轨迹概率]]还有[[广义自由能]]的关系. 在平衡态系统中, 我们可以定义一个分布的[[广义自由能]]

$$
F_{neq}(\rho(x)) =  D_{KL}(\rho(x)||\rho^{eq}(x))  = \langle H(X)\rangle-kTH(X)
$$

我们可以由此得到标准的热力学第二定律:

$$
W\geq F_{fin}-F_{init}=\Delta F
$$

如果是一个联合概率分布, 我们怎么去定义广义自由能呢? 可能是一部分平衡而另一部分不平衡?

$$
F(X,M) = \langle H(X,M)\rangle - kT H(X,M)
$$

然后由此我们可以得到带有测量的second law of thermodynamics

$$
W\geq \Delta F - kT I(X,M)
$$
这里我们要回去看一看. 系统的非平衡自由能的定义是清晰的, 也就是系统和测量系统都处于非平衡态的能量. 

$$
\begin{aligned}
F(X,M)^{neq} 
&= \int_X\int_M \rho(x,m)\ln\frac{\rho(x,m)}{\rho^{eq}(x,m)}\\
&= \int_X\int_M \rho(x,m)\ln \left[\frac{\rho(x,m)}{\rho(x)\rho(m)} \frac{\rho(x)\rho(m)}{\rho^{eq}(x,m)}\right]\\
& = I^{neq}(x,m) - \int_X\int_M\rho(x,m)\ln\frac{\rho(x)\rho(m)}{\rho^{eq}(x,m)}
\end{aligned}
$$
在平衡态我有没有 $I(X,Y)=0$? 这意味着 $p(x,y)= p(x)p(y)$, 也就是 $p(x|y) = p(x)$.

如果是一个Markov network, 第一个系统有 $N_x$ 个状态, 第二个系统有 $N_y$ 个状态, 那总共就是 $N_x\times N_y$ 个状态. 如果我们算整个系统的corss-correlation, 算的是什么呢? 比如我们可以算处在两种系统之间的cross-correlation, 那么有 


### 互信息的例子
考虑两个随机变量 $X = [0,1]$ 以及 $Y = [0,1]$, 如何计算互信息? 我们总共有四个状态

$$
(0,0),\,(0,1),\,(1,1),\,(1,0)
$$
那么 $P(x)$ 是怎么表达的呢?
$$
p_x(0) = p_{x,y}(0,0)+p_{x,y}(0,1),\quad p_x(1) = p_{x,y}(1,0)+p_{x,y}(1,1).
$$
然后 $P(x|y)$ 是怎么表达的呢?

$$
p_{x|y}(0,0)= \frac{p_{x,y}(0,0)}{p_y(0)} = \frac{p_{x,y}(0,0)}{p_{x,y}(0,0)+p_{x,y}(0,1)}
$$
如果我们计算互信息, 则需要计算 $H(x)$ 以及 $H(x|y)$

$$
\begin{aligned}
H(x)
=& -\sum_x p_x\ln p_x \\
=& -\left[p_{x,y}(0,0)+p_{x,y}(0,1)\right]\ln\left[p_{x,y}(0,0)+p_{x,y}(0,1)\right]\\
&-\left[p_{x,y}(1,0)+p_{x,y}(1,1)\right]\ln\left[p_{x,y}(1,0)+p_{x,y}(1,1)\right]
\end{aligned}
$$
$$
\begin{aligned}
	H(x|y) 
	=& -\sum_y p_y \sum_x p_{x|y}\ln p_{x|y}\\
	=&-p_{x,y}(0,0)\ln p_{x,y}(0,0)
\end{aligned}
$$