不妨先用香农的信息

$$
S = -\sum_i p_i\ln p_i
$$

如果我们有两组不同的概率分布 $P=\{p_i\}$ 与 $P'=\{p_i'\}$ ，我们想度量这两组概率分布之间的距离，那我们可以用[[相对熵]]，也称为KL散度来定义“KL divergence”

 